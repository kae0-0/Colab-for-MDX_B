{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "q6cO88PPsPfa"
      },
      "source": [
        "#<font color=\"Red\">MDX Colab with new UVR models</font><br>\n",
        "\n",
        "It downloads all models automatically. <br>No manual models.py replacing necessary for various models\n",
        "\n",
        "<sup><br>If you have \"vocals.onnx not found\" check ForceUpdate or delete MDX_Colab folder from your GDrive, terminate the session and start over.\n",
        "\n",
        "<sup><br>Models provided are from [Kuielab](https://github.com/kuielab/mdx-net-submission/), [UVR](https://github.com/Anjok07/ultimatevocalremovergui/) and [Kim](https://github.com/KimberleyJensen/) <br> (you can support UVR [here](https://www.buymeacoffee.com/uvr5/vip-model-download-instructions) and [here](https://boosty.to/uvr)).</sup></br>\n",
        "<sup><br>Notebook by [Audio Hacker](https://www.youtube.com/channel/UC0NiSV1jLMH-9E09wiDVFYw/), modified by Audio Separation community.</sup></br> \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "H_cTbwhVq4K6"
      },
      "outputs": [],
      "source": [
        "initialised = True\n",
        "from time import sleep\n",
        "from google.colab import output\n",
        "from google.colab import drive\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "import psutil\n",
        "import glob\n",
        "\n",
        "ai = 'https://github.com/kae0-0/Colab-for-MDX_B'\n",
        "ai_version = 'https://github.com/kae0-0/Colab-for-MDX_B/raw/main/v'\n",
        "onnx_list = 'https://raw.githubusercontent.com/kae0-0/Colab-for-MDX_B/main/onnx_list'\n",
        "#@title Initialise MDX\n",
        "#@markdown Mounting to drive\n",
        "mount_to_drive = True #@param {type:\"boolean\"}\n",
        "#@markdown Mounting path (used only if mount_to_drive is ticked)\n",
        "mount_path = '/content/drive/MyDrive' #@param [\"snippets:\",\"/content/drive/MyDrive\",\"/content/drive/Shareddrives/<your shared drive name>\", \"/content/drive/Shareddrives/Shared Drive\"]{allow-input: true}\n",
        "ForceUpdate = False #@param {type:\"boolean\"}\n",
        "class h:\n",
        "    def __enter__(self):\n",
        "        self._original_stdout = sys.stdout\n",
        "        sys.stdout = open(os.devnull, 'w')\n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        sys.stdout.close()\n",
        "        sys.stdout = self._original_stdout\n",
        "def get_size(bytes, suffix='B'): # read ram\n",
        "    global svmem\n",
        "    factor = 1024\n",
        "    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\"]:\n",
        "        if bytes < factor:\n",
        "            return f'{bytes:.2f}{unit}{suffix}'\n",
        "        bytes /= factor\n",
        "    svmem = psutil.virtual_memory()\n",
        "def console(t):\n",
        "    get_ipython().system(t)\n",
        "def LinUzip(file): # unzip call linux, force replace\n",
        "    console(f'unzip -o {file}')\n",
        "#-------------------------------------------------------\n",
        "def getONNX():\n",
        "    console(f'wget {onnx_list} -O onnx_list')\n",
        "    _onnx = open(\"onnx_list\", \"r\")\n",
        "    _onnx = _onnx.readlines()\n",
        "    os.remove('onnx_list')\n",
        "    for model in _onnx:\n",
        "        _model = sanitize_filename(os.path.basename(model))\n",
        "        console(f'wget {model}')\n",
        "        LinUzip(_model)\n",
        "        os.remove(_model)\n",
        "    \n",
        "\n",
        "def getDemucs(_path):\n",
        "    #https://dl.fbaipublicfiles.com/demucs/v3.0/demucs_extra-3646af93.th\n",
        "    root = \"https://dl.fbaipublicfiles.com/demucs/v3.0/\"\n",
        "    model = {\n",
        "        'demucs_extra': '3646af93'\n",
        "    }\n",
        "    for models in zip(model.keys(),model.values()):\n",
        "        console(f'wget {root+models[0]+\"-\"+models[1]}.th -O {models[0]}.th')\n",
        "    for _ in glob.glob('*.th'):\n",
        "        if os.path.isfile(os.path.join(os.getcwd(),_path,_)):\n",
        "            os.remove(os.path.join(os.getcwd(),_path,_))\n",
        "        shutil.move(_,_path)\n",
        "def mount(gdrive=False):\n",
        "    if gdrive:\n",
        "        try:\n",
        "            drive.mount(\"/content/drive\", force_remount=True)\n",
        "        except:\n",
        "            drive._mount(\"/content/drive\", force_remount=True)\n",
        "    else:\n",
        "        pass\n",
        "def toPath(path='local'):\n",
        "    if path == 'local':\n",
        "        os.chdir('/content')\n",
        "    elif path == 'gdrive':\n",
        "        os.chdir(mount_path)\n",
        "\n",
        "def update():\n",
        "    with h():\n",
        "        console(f'wget {ai_version} -O nver')\n",
        "    f = open('nver', 'r')\n",
        "    nver = f.read()\n",
        "    f = open('v', 'r')\n",
        "    cver = f.read()\n",
        "    if nver != cver or ForceUpdate:\n",
        "        print('New update found! {}'.format(nver))\n",
        "        os.chdir('../')\n",
        "        print('Updating ai...',end=' ')\n",
        "        with h():\n",
        "            console(f'git clone {ai} temp_MDX_Colab')\n",
        "            console('cp -a temp_MDX_Colab/* MDX_Colab/')\n",
        "            console('rm -rf temp_MDX_Colab')\n",
        "        print('done')\n",
        "        os.chdir('MDX_Colab')\n",
        "        print('Refreshing models...', end=' ')\n",
        "        with h():\n",
        "            getDemucs('model/')\n",
        "            getONNX()\n",
        "        print('done')\n",
        "        output.clear()\n",
        "        os.remove('v')\n",
        "        os.rename(\"nver\",'v')\n",
        "        #os.chdir(f'{os.path.join(mount_path,\"MDX_Colab\")}')\n",
        "    else:\n",
        "        os.remove('nver')\n",
        "        print('Using latest version.')\n",
        "\n",
        "def past_installation():\n",
        "    return os.path.exists('MDX_Colab')\n",
        "\n",
        "def LoadMDX():\n",
        "    console(f'git clone {ai} MDX_Colab')\n",
        "\n",
        "#-------------------------------------------------------\n",
        "# install requirements\n",
        "print('Installing dependencies will take 45 seconds...',end=' ')\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('command not found') >= 0:\n",
        "    svmem = psutil.virtual_memory()\n",
        "    gpu_runtime = False\n",
        "    with h():\n",
        "        console('pip3 -q install onnxruntime==1.14.1')\n",
        "else:\n",
        "    gpu_runtime = True\n",
        "    with h():\n",
        "        console('pip3 -q install onnxruntime-gpu==1.14.1')\n",
        "with h():\n",
        "    deps = [\n",
        "            'pathvalidate',\n",
        "            'youtube-dl',\n",
        "            'django'\n",
        "    ]\n",
        "    for dep in deps:\n",
        "        console('pip3 -q install {}'.format(dep))\n",
        "# import modules\n",
        "#console('pip3 -q install torch==1.13.1')\n",
        "console('pip3 -q install soundfile==0.12.1')\n",
        "console('pip3 -q install librosa==0.9.1')\n",
        "from pathvalidate import sanitize_filename\n",
        "print('done')\n",
        "if not gpu_runtime:\n",
        "    print(f'GPU runtime is disabled. You have {get_size(svmem.total)} RAM.\\nProcessing will be incredibly slow. ðŸ˜ˆ')\n",
        "elif gpu_info.find('Tesla T4') >= 0:\n",
        "    print('You got a Tesla T4 GPU. (speeds are around  10-25 it/s)')\n",
        "elif gpu_info.find('Tesla P4') >= 0:\n",
        "    print('You got a Tesla P4 GPU. (speeds are around  8-22 it/s)')\n",
        "elif gpu_info.find('Tesla K80') >= 0:\n",
        "    print('You got a Tesla K80 GPU. (This is the common gpu, speeds are around 2-10 it/s)')\n",
        "elif gpu_info.find('Tesla P100') >= 0:\n",
        "    print('You got a Tesla P100 GPU. (This is the Second to the fastest gpu, speeds are around  15-42 it/s)')\n",
        "else:\n",
        "    if gpu_runtime:\n",
        "        print('You got an unknown GPU. Please report the GPU you got!')\n",
        "        ! nvidia-smi\n",
        "#console('pip3 -q install demucs')\n",
        "#-------------------------------------------------------\n",
        "# Scripting\n",
        "mount(mount_to_drive)\n",
        "toPath('gdrive' if mount_to_drive else 'local')\n",
        "#check for MDX existence\n",
        "if not past_installation():\n",
        "    print('First time installation will take around 3-6 minutes.\\nThis requires around 2-3 GB Free Gdrive space.\\nPlease try not to interup installation process!!')\n",
        "    print('Downloading AI...',end=' ')\n",
        "    with h():\n",
        "        LoadMDX()\n",
        "    os.chdir('MDX_Colab')\n",
        "    print('done')\n",
        "    \n",
        "    print('Downloading models...',end=' ')\n",
        "    with h():\n",
        "        getDemucs('model/')\n",
        "        getONNX()\n",
        "    if os.path.isfile('onnx_list'):\n",
        "        os.remove('onnx_list')\n",
        "    print('done')\n",
        "\n",
        "else:\n",
        "    os.chdir('MDX_Colab')\n",
        "    update()\n",
        "\n",
        "################\n",
        "#outro\n",
        "print('Success!')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hakZKxmTtaHn"
      },
      "source": [
        "#<font color=\"Red\">Inference</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NS5gkRxlj-2B"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Print a list of tracks\n",
        "for i in glob.glob('tracks/*'):\n",
        "    print(os.path.basename(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "UHIQxwkUtSDa"
      },
      "outputs": [],
      "source": [
        "if not 'initialised' in globals():\n",
        "    raise NameError('Please run the first cell first!! #scrollTo=H_cTbwhVq4K6')\n",
        "\n",
        "#import all models metadata\n",
        "import json\n",
        "with open('model_data.json', 'r') as f:\n",
        "  model_data = json.load(f)\n",
        "\n",
        "# Modifiable variables\n",
        "tracks_path = 'tracks/'\n",
        "separated_path = 'separated/'\n",
        "\n",
        "#@markdown ### Input track\n",
        "#@markdown Enter any link/Filename (Upload your songs in tracks folder)\n",
        "track = \"Butterfly.wav\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Models\n",
        "ONNX = \"MDX-UVR Ins Model Full Band 498 (HQ_2)\" #@param [\"off\", \"Karokee\", \"Karokee_AGGR\", \"Karokee 2\", \"baseline\", \"MDX-UVR Ins Model 415\", \"MDX-UVR Ins Model 418\", \"MDX-UVR Ins Model 464\", \"MDX-UVR Ins Model 496 - inst main-MDX 2.1\", \"Kim ft other instrumental model\", \"MDX-UVR Vocal Model 406\", \"MDX-UVR Vocal Model 427\", \"MDX-UVR-Kim Vocal Model (old)\", \"MDX-UVR-Kim Vocal Model 2 (Kim vocal 2)\", \"MDX-UVR Ins Model Full Band 292\", \"MDX-UVR Ins Model Full Band 403\", \"MDX-UVR Ins Model Full Band 450 (HQ_1)\", \"MDX-UVR Ins Model Full Band 498 (HQ_2)\", \"(de)Reverb HQ By FoxJoy\"]\n",
        "Demucs = 'off'#@param [\"off\",\"demucs_extra\"]\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Parameters\n",
        "denoise = False #@param {type:\"boolean\"}\n",
        "normalise = True #@param {type:\"boolean\"}\n",
        "#getting values from model_data.json related to ONNX var (model folder name)\n",
        "amplitude_compensation = model_data[ONNX][\"compensate\"]\n",
        "dim_f = model_data[ONNX][\"mdx_dim_f_set\"]\n",
        "dim_t = model_data[ONNX][\"mdx_dim_t_set\"]\n",
        "n_fft = model_data[ONNX][\"mdx_n_fft_scale_set\"]\n",
        "\n",
        "mixing_algorithm = 'min_mag' #@param [\"default\",\"min_mag\",\"max_mag\"]\n",
        "chunks = 55 #@param {type:\"slider\", min:1, max:55, step:1}\n",
        "shifts = 10 #@param {type:\"slider\", min:0, max:10, step:0.1}\n",
        "\n",
        "##validate values\n",
        "track = track if 'http' in track else tracks_path+track\n",
        "normalise = '--normalise' if normalise else ''\n",
        "denoise = '--denoise' if denoise else ''\n",
        "\n",
        "if ONNX == 'off':\n",
        "    pass\n",
        "else:\n",
        "    ONNX = 'onnx/'+ONNX\n",
        "if Demucs == 'off':\n",
        "    pass\n",
        "else:\n",
        "    Demucs = 'model/'+Demucs+'.th'\n",
        "#@markdown ---\n",
        "#@markdown ### Stems\n",
        "bass = False #@param {type:\"boolean\"}\n",
        "drums = False #@param {type:\"boolean\"}\n",
        "others = False #@param {type:\"boolean\"}\n",
        "vocals = True #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "#@markdown ### Invert stems to mixture\n",
        "invert_bass = False #@param {type:\"boolean\"}\n",
        "invert_drums = False #@param {type:\"boolean\"}\n",
        "invert_others = False #@param {type:\"boolean\"}\n",
        "invert_vocals = True #@param {type:\"boolean\"}\n",
        "invert_stems = []\n",
        "stems = []\n",
        "if bass:\n",
        "    stems.append('b')\n",
        "if drums:\n",
        "    stems.append('d')\n",
        "if others:\n",
        "    stems.append('o')\n",
        "if vocals:\n",
        "    stems.append('v')\n",
        "\n",
        "invert_stems = []\n",
        "if invert_bass:\n",
        "    invert_stems.append('b')\n",
        "if invert_drums:\n",
        "    invert_stems.append('d')\n",
        "if invert_others:\n",
        "    invert_stems.append('o')\n",
        "if invert_vocals:\n",
        "    invert_stems.append('v')\n",
        "\n",
        "margin = 44100\n",
        "\n",
        "###\n",
        "# incompatibilities\n",
        "###\n",
        "\n",
        "console(f\"python main.py --n_fft {n_fft} --dim_f {dim_f} --dim_t {dim_t} --margin {margin} -i \\\"{track}\\\" --mixing {mixing_algorithm} --onnx \\\"{ONNX}\\\" --model {Demucs} --shifts {round(shifts)} --stems {''.join(stems)} --invert {''.join(invert_stems)} --chunks {chunks} --compensate {amplitude_compensation} {normalise} {denoise}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lOmAsaSTha39"
      },
      "source": [
        "Model parameters (not necessary anymore)<br><br>\n",
        "-*Fullband*: <br>self.n_fft = **6144** dim_f = **3072** dim_t = **8**<br><br>\n",
        "-*kim vocals, ft other, inst 1-3 (415-464), 427*:<br> self.n_fft = **7680** dim_f = **3072** dim_t = **8**<br><br>\n",
        "-*496, Karaoke, 9.X (NET-X)*<br>\n",
        "self.n_fft = **6144** dim_f = **2048** dim_t = **8** (and **9** kuielab_a_vocals only)<br><br>\n",
        "-Karaoke 2<br>\n",
        "self.n_fft = **5120** dim_f = **2048** dim_t = **8**\n",
        "<br><br>\n",
        "You can use fullband config for e.g. kim ft other, so it will uncap the 17.7kHz cutoff, giving much less muddy output, but it will strongly amplify vocal residues (still, might be useful in some cases).\n",
        "<br><br>\n",
        "Volume compensation values (not necessary)<br><br>\n",
        "-1.02/1.022099 is for Kim other ft (the 1st value recommended)<br>\n",
        "-1.03 value is for \"vocal\" models e.g. 427 (and Kim vocal and 9.7 [NET 1]) <br>\n",
        "-1.033/1.035437 is for HQ_2<br>\n",
        "-1.05 *compensation* value is for \"inst\" models (e.g. 464 a.k.a. inst 3) <br>\n",
        "-1.08 (old) for e.g. 418 model with normalization disabled and chunks 1 (less muddy result for min_mag, sometimes more instruments disappearing, also vs 464)<br>\n",
        "\n",
        "The value above may differ also toward different tracks. Also, amplitude compensation doesn't change inverted stem.\n",
        "- Donâ€™t disable *invert_vocals* in Colab even if you only need one stem, otherwise the Colab will end up with error.<br>\n",
        "- If you won't change any options above, these are the optimized settings for instrumentals with low amount of vocal residues and high quality (for less vocal residues but worse quality, you can also check inst3 and kim ft models).<br>\n",
        "- Separating same track with different model will be replaced the old result (rename files manually if necessary)\n",
        "- Inversion applied for second stem allowing getting vocals from instrumental models or vice versa - to get instrumentals from vocal models.\n",
        "- Output file names for instrumental models will be swapped because the Colab originally was wrtitten for vocal models.<br> \n",
        "- In case of memory allocation error (especially with Demucs on), change chunks to 20 or 40 (the more chunks the lower vocal popups and sometimes vocal residues - fixed in UVR5 GUI in batch mode).<br> \n",
        "-In case of *system error* with input file name written, retry separation or ensure you wrote your file name correctly.<br>\n",
        "-In case of *shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory* go to environment and terminate session and start over.<br>\n",
        "- Downloading result files with Colab file manager can be (very) slow, and multiple file downloading may eventually download only one file - use GDrive instead. \n",
        "- Don't add shortcuts to tracks folder. The Colab will not output files properly.\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "**Settings explanation**<br>\n",
        "\n",
        "*Mixing algorithm* - max_mag - is generally for vocals (gives the most residues in instrumentals), min_mag - for instrumentals (the most aggresive) though \"min_mag solve some un-wanted vocal soundings, but instrumental [is] more muffled and less detailed\". Check out also \"default\" as it's in between both - a.k.a. average (it's also required for Demucs enabled which works only for vocal models).<br>\n",
        "\n",
        "*Chunks* - Set it to 55 or 40 (less aggressive) to alleviate some occasional instrument dissapearing.\n",
        "Set 1 for the best clarity. It works for at least instrumental model (4:15 track, at least for Tesla T4 (shown at the top) generally better quality, but some instruments tend to disappear more using 1 than 10. For Demucs enabled and/or vocal model it can be set to 10 if your track is below 5:00 minutes. The more chunks, the faster separation up to ~40. For 4:15 track, 72 is max supported till memory allocation error shows up (disabled chunks returns error too). <br>\n",
        "\n",
        "*Shifts* - can be set max to 10, but it only slightly increases SDR, while processing time is 1.7x longer for each shift and it gives similar result to shifts 5.\n",
        "\n",
        "*Normalization* - \"normalizes all input at first and then changes the wave peak back to original. This makes the separation process better, also less noise\" (e.g. if you have to noisy hihats or big amplitude compensation - disable it).\n",
        "<br>\n",
        "\n",
        "*Demucs* enabled works correctly with mixing algorithm set to default and only with vocal models (Kim and 427). It's also the only option to get rid of noise of MDX models. Normalization enabled is necessary (but that cnfiguration has slightly more vocal residues than instrumental model). Decrease chunks to 40 if you have ONNXRuntimeError with Demucs on (it requires lower chunks).\n",
        "<br><br>\n",
        "\n",
        "*Recommended models*\n",
        "\n",
        "For instrumentals:\n",
        "- HQ_2 (best quality; normal vs min_mag less muddy, more vocal residues)\n",
        "\n",
        "- kim ft other (if you have vocal residues with HQ models, but not always)\n",
        "\n",
        "- inst 3/464 (if it's still a bit noisy)\n",
        "\n",
        "- HQ_1 with 1.05 v. comp. (less muddy vs HQ_2 w/ v. 1.033, but more vocal residues, I like it)\n",
        "\n",
        "For vocals:\n",
        "- kim vocal (less instrumental residues in vocal stem)\n",
        "<br>or alternatively\n",
        "- 427 \n",
        "- 406 (soon)\n",
        "\n",
        "For lead vocals:\n",
        "- Karaokee 2\n",
        "\n",
        "For backing vocals:\n",
        "- [HP_KAROKEE-MSB2-3BAND-3090](https://colab.research.google.com/drive/16Q44VBJiIrXOgTINztVDVeb0XKhLKHwl?usp=sharing)\n",
        "\n",
        "<br>\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2FetQwdcXBef"
      },
      "source": [
        "Changelog\n",
        "<br><br>\n",
        "Kim's vocal model is \"old\" only in a sense that she already had a newer one at some point, but it was the best evaluated single vocal model by [SDR](https://mvsep.com/quality_checker/leaderboard.php?ensemble=0) available publically for 12.03.23 (now only surpassed by MDX23 on mvsep1.ru).\n",
        "\n",
        "<sup>Added 292 full band beta instrumental model (no 14.7kHz cutoff). 292 epoch already [surpased](https://mvsep.com/quality_checker/leaderboard2.php?&sort=instrum&page=20) Demucs 4 ft model. 309 and 337 epochs are already better than inst 1 SDR-wise.\n",
        "\n",
        "<sup>Newly added 403 full band beta instrumental model (no 14.7kHz cutoff) - should be better than the 293 in most if not all cases.<br></sup>\n",
        "Final full band 450 (HQ_1) instrumental model addeded (it may leave more vocal residues than inst3 at times, but it's really worth trying out).<br>\n",
        "Newer 498 epoch added (HQ_2) \"better at removing long drawn out vocals\"<br>\n",
        "Kim other ft model added (the best SDR, even vs 464, but it has cutoff), read point 16.<br>\n",
        "I've reverted old \"Karokee\" and \"Karokee_AGGR\" models, but these are old models (maybe they will do the trick, though), they're already in your MDX_Colab folder after mounting.<br>\n",
        "Python 3.10 fix by Crusty Crab.<br>\n",
        "Denoiser and model parameter picker by jarredou. <br>\n",
        "Karaokee 2 model. Forgot adding it to the list.<br>\n",
        "Torch 2.0 fix by jarredou. Colab installation speed-up.<br>\n",
        "Fixed torch fix."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "O8F0M-HyKfks"
      },
      "source": [
        "In case of persistent vocals.onnx error - manual installation of [model files](https://docs.google.com/document/d/17fjNvJzj8ZGSer7c7OFe_CNfUKbAxEh_OBv94ZdRG5c/edit#heading=h.aa2xhwp434) files."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
